\documentclass[12pt]{article}

\usepackage{sbc-template}

\usepackage{graphicx,url}
\usepackage{float}
\usepackage{verbatim}
\usepackage[english]{babel}

\sloppy

\title{}

\author{Adriano M. Gil\inst{1}, Thiago S. Figueira\inst{1}}

\address{SIDIA Instituto de Ci\^encia e Tecnologia
  (SIDIA)\\
  Manaus -- AM -- Brazil
  \email{\{adriano.gil,t.figueira\}@sidia.com}
}

\begin{document}

\maketitle

\begin{abstract}
    Virtual reality applications are very sensitive to synchronization delays between user movements and their consequences on the virtual environment. A way to mitigate this issue is to move its implementation to the GPU. In this work, we propose an architecture of game visualization based on a shader. As an example of this approach, we implemented the classic game Snake in which every visual element is defined and rendered by the shader in a unique mesh.
\end{abstract}

\smallskip

\noindent \textbf{Keywords:} Unity, shaders, virtual reality games.

\section{Introduction} 
Virtual reality (VR) brings the promise of a revolution in the way entertainment is consumed in modern times. The user is placed at the center of the action and perceives content from every direction. Games, for their part,  transport players to a world envisioned by game developers and designers. As the technology for other form factors such as PC and console advances, VR players want life-like graphics and improved responsiveness. 

Regarding VR games development, Unity is the most used engine, and even though it is optimized, we believe there is an opportunity in exploring graphics cards for additional performance. Games developed in Unity follow a graphical pipeline where, generally speaking, the CPU (central processing unit) is responsible for transmitting graphics information to the GPU (graphics processing unit) through the Application stage, where the VRAM (video random access memory) loads graphics assets such as 3D models and textures. Afterward, during the Geometry stage, different objects and their information (positioning, for example) are handled by the GPU. The final stage, Rasterization, is where those objects become images.

\section{Related Work}
The two-dimensional game \textit{GPGPUWars} \cite{GPGPUWars} has its code structure based on \textit{shaders}, it is similar to the architecture presented here where the GPU performs all the processing of the game. However, applications in virtual reality differ from other applications since there is the need to fill the three-dimensional space to provide content for 3 degrees of freedom (3DoF-\textit{3 Degrees of Freedom}). For example, the application described in \cite{zund2015unfolding} uses computational vision to generate a panoramic view of an 8-bit console game. Running on a \textit{Oculus Rift DK2}, the virtual reality device from \textit{Facebook}, the player is positioned in the center of the world and as he moves his character, the world is revealed around him, extending the game view to the four walls of the virtual environment.

\section{VRSnake} \label{sec:vrsnake}
\textit{VRSnake} brings to virtual reality the classic 2D game \textit{Snake}, but unlike the original, the player controls the positioning of the collectible objects rather than directly controlling the snake. We propose the following rules: 

The snake continuously and automatically seeks the collectible object and grows in a unit as it reaches this object. As in the original game, the serpent must move in a circular way through the scenario, that is, when it finds the boundaries of the scenario on one side, it must continue its movement on the other side. The player wins when the \textit{snake} is defeated, that is, when it hits itself in some way. In addition, the snake's search behavior must ensure that there is no movement towards its own body, but also that there is a randomization factor during movement to guarantee unpredictability.

\section{Shader-based visualization architecture}
 \label{sec:architecture}
There are two approaches to the game architecture: in the first one, we use two layers of the graphics pipeline, and in the second one, we use a single layer. In the first approach, one layer is responsible for handling the logic of the game while the other is accountable for managing the rendering.  The logical layer controls intelligent tasks such as the search for the collectible objects and movement, furthermore, it is executed in the Central Processing Unit (CPU) in CSharp. The visualization layer involves a shader, a piece of code that runs directly in the Graphics Processing Unit (GPU), which is responsible for rendering all items displayed on the output device, which includes the collectible objects as well as the snake.

In other words, the logical layer manages the collision and movement of the snake as well as selects the most promising path given a randomization factor; The visualization layer, on the other hand, is responsible for rendering all the elements arranged in the output device, that is, the CPU has no influence over these objects.

\section{Virtual reality in a inverted sphere}
The illusion in a virtual world and the consequent immersion sensation that comes with it requires visual material available from all possible angles as the \textit{gearVR} allows complete freedom of rotation, i.e. 3 degrees of Freedom (3DoF-\textit{3 degrees of Freedom}). Given that our proposal contemplates a 2D game, there is the challenge of displaying two-dimensional content in a 3D scenario so that everything happens around the user.

An inverted sphere, that is, a sphere that has only its inner side rendered, makes it possible to completely fill the entire field of view, it also is the standard solution adopted to display equirectangular images in 360 degrees. The procedural generation of a sphere can follow one of the two approaches below:

\begin{enumerate}
  \begin{item} An icosphere, i.e., a sphere which vertices are evenly distributed;
 \end{item}
  \begin{item} Generation of vertices based on longitude/latitude coordinates. \end{item}
\end{enumerate}

For this work, the second approach was adopted due to the possibility of using longitude/latitude as a way to map the UV coordinates through the equation below:

\begin{equation}
R^2 \leftarrow R^3 : (\lambda, \theta) \rightarrow (x, y, z)
\label{equation1}
\end{equation}

\section{Snake movement agent} \label{sec:agent}

The movement of the \textit{snake} is composed of a state evaluation function that analyzes each possible action at any given time. In essence, the serpent is always seeking  the collectible, so it evaluates the shortest distance course on the X and Y axes in the UV space and, provided that there is no possibility of hitting itself, takes this path and repeats the process. The function below illustrates this procedure:

\begin{equation}
F(A) = R * (D + O)
\label{equation11}
\end{equation}

Where \textit{R} is a randomization factor; \textit{D} represents the \textit{Manhattan} distance between the current position and the collectable object; And \textit{O} is a value attributed to the existence or not of obstacles in this path.

The movement logic manages the positioning of the head and body of the serpent.  In other words, the head guides all the movements of the \textit{snake}. Three vectors are  responsible for guiding the serpent in the decision of the smallest path between its current position and the collectible object. It is relevant to clarify that these targeting vectors are changed given the different positions the snake can adopt

The body of the serpent, in its turn, moves through a sliding \textit{buffer}: each part of the body assumes the most recent position of the immediately preceding part, this means that the head moves and the other parts follow afterwards.

\section{Conclusions}


\bibliographystyle{sbc}
\bibliography{hci-abstract}

\end{document}